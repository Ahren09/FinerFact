[pagerank]
num_sents = 6
num_topics = 20
num_words_per_topic = 7

[gat.social]
num_claims = 5
num_sents_in_each_pair = 3
num_tweets_in_each_pair = 6
num_users = 32
do_padding_topics = no
do_padding_sents = false

[KGAT]

learning_rate = 5e-5
gradient_accumulation_steps = 8

dropout = 0.6
; kernel = 21
; The maximum total input sequence length after WordPiece tokenization.
; Sequences longer than this will be truncated, and sequences shorter than this will be padded.
max_len = 130
evi_num = 5
train_batch_size = 2
valid_batch_size = 2
num_train_epochs = 20
; ------------------------
; Params for the new KGAT
; ------------------------

cuda = True
; dataset = gossipcop
dataset = politifact
; mode can be article, tweet, pr, joint
keep_claim = True
only_claim = True
linear_weight_mean = 0
linear_weight_std = 1e-4
mode = FF
; only supports BERT for now
model_name = bert-base-cased
test_size = 0.2
translation_mat_weight_mean = 0
translation_mat_weight_std = 1e-4
user_embed_dim = 64
warmup_ratio = 0.06
pretrained_user_embed = false

enable_tensorboard = false
enable_fitlog = false


[TEST]
test_user_embed = false
